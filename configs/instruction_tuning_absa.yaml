model:
 load_in_4bit: True
 use_cache: False

 # model config
 model_name: ???
 # device config
 device: "cuda"
 # output dir for saved model
 output_dir: ???

 # label aspects
 label_aspects: ["Safety", "Cleanliness", "Data availability", "Price fairness", 
 "User-friendly payment system", "Start quality", "Satisfactions", "Facilities at station",
 "Facilities within train", "Accessibility for disabilities", "Maintenance", 
 "Punctuality", "Ease of connections between lines", "Reliability equipment", 
 "Accidents", "Others"]
 
 # label polarity
 label_polarities: ["positive", "negative", "neutral"]

 # instruction style
 instruction_style: simple # multi-task or simple

 # bit and bytes config
 bitandbytes_config:
   # bnb_4bit_compute_dtype: ???
   bnb_4bit_quant_type: 'nf4'
   bnb_4bit_use_double_quant: True

  # peft config
 peft_config:
   alpha: 16
   lora_dropout: 0.1
   peft_r: 64
   peft_bias: 'none'
   task_type: "CAUSAL_LM"

 # train parameters
 train:
  # SFTTrainer
  train_dir: ???
  dev_dir: ???
  test_dir: ???
  epoch: 2
  batch: 8
  lr: 2e-4
  optimizer: "adamw_torch_fused"
  max_seq_len: 3072
  packing: True
  gradient_accumulation_steps: 2
  gradient_checkpointing: True
  logging_steps: 100
  bf16: True
  tf32: False
  max_grad_norm: 0.3
  warmup_ratio: 0.3
  lr_scheduler_type: "constant"
  push_to_hub: False
  report_to: "wandb"
