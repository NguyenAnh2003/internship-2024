{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2dqimZ6k8cV"
      },
      "outputs": [],
      "source": [
        "!pip install transformers google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFHnbWm8WMqd"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpQGey_jk_kb"
      },
      "outputs": [],
      "source": [
        "model_name = \"facebook/bart-large-mnli\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6N2t_sVWPOO"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpJpDlaRWtfk"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HatqPmsRWw5P"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bTVSpvUwPUk"
      },
      "outputs": [],
      "source": [
        "GEMINI_APIKEY = \"AIzaSyCNz3xJdaUsRgKNsVjlFvh5EkSPafiNEBs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usYmisoJnPaR"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import google.generativeai as genai\n",
        "\n",
        "class DataInference:\n",
        "  def __init__(self, model_name, device):\n",
        "    self.model_name = model_name\n",
        "    self.device = device\n",
        "    self.task = \"zero-shot-classification\"\n",
        "    self.classifier = pipeline(self.task, model=model_name)\n",
        "    self.gemini_name = \"gemini-1.5-flash\"\n",
        "    api_key = GEMINI_APIKEY\n",
        "    genai.configure(api_key=api_key)\n",
        "\n",
        "    # safety setting\n",
        "    safety_setting = [\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "            \"threshold\": \"BLOCK_NONE\"\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "            \"threshold\": \"BLOCK_NONE\"\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "            \"threshold\": \"BLOCK_NONE\"\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "            \"threshold\": \"BLOCK_NONE\"\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    # llm prediction\n",
        "    self.llm = genai.GenerativeModel(self.gemini_name, safety_settings=safety_setting)\n",
        "\n",
        "  def extract_aspect(self, sentence):\n",
        "    # candidate labels\n",
        "    labels = [\"Price fairness\", \"Cleanliness\", \"Facilities\", \"Staff quality\", \"Convenience\",\n",
        "              \"Punctuality\", \"Accessibility\", \"Safety\", \"Data availability\"]\n",
        "\n",
        "    # get result\n",
        "    aspect = self.classifier(sentence, labels)\n",
        "    return aspect\n",
        "\n",
        "  def get_sentiment_based_on_aspect(self, sentence, aspect):\n",
        "    labels = [\"Positive\", \"Negative\", \"Neutral\"]\n",
        "    result = self.classifier(sentence, labels)\n",
        "    return result\n",
        "\n",
        "  def llm_prediction(self, prompt):\n",
        "    try:\n",
        "      response = self.llm.generate_content(prompt)\n",
        "      return response.text\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      raise ValueError(e)\n",
        "\n",
        "  def inference_pipeline(self, review):\n",
        "    r1 = self.extract_aspect(review) # return dict with sequence, labels and score\n",
        "    aspects = r1[\"labels\"]\n",
        "    scores = r1[\"scores\"]\n",
        "\n",
        "    # mapping aspect score\n",
        "    aspect_score = dict(zip(aspects, scores))\n",
        "\n",
        "    # threshold\n",
        "    threshold = 0.22\n",
        "\n",
        "    # getting aspect more than threshold\n",
        "    aspect_score = {k: v for k, v in aspect_score.items() if v > threshold}\n",
        "    aspectss = list(aspect_score.keys())\n",
        "\n",
        "    rs = []\n",
        "\n",
        "    for idx, aspect in enumerate(aspectss):\n",
        "      prompt = f\"\"\"Get the opinion of user in this review: {review} that corresponded to aspect: {aspect}\n",
        "      ***EXAMPLE***\n",
        "      review example: 'I am impressed about the cleanliness, facilitiy at station is really good'\n",
        "      output: 'Impressed about cleanliness'\n",
        "      ***NOTE***\n",
        "      Do not have any markup syntax used in Markdown.\n",
        "      Do not have symbol '\\n' and the end or start\n",
        "      Do not summarize the review\n",
        "      The output must be original do not change the text\n",
        "      \"\"\"\n",
        "      opinion = self.llm_prediction(prompt).replace(\"\\n\", \"\").strip()\n",
        "      result = self.get_sentiment_based_on_aspect(opinion, aspect)\n",
        "\n",
        "      # mapping sentiment with score\n",
        "      sentiments = result[\"labels\"]\n",
        "      score = result[\"scores\"]\n",
        "      sentiment_score = dict(zip(sentiments, score))\n",
        "      sentiment = max(sentiment_score, key=sentiment_score.get)\n",
        "      rs.append({\"aspect\": aspect, \"sentiment\": sentiment, \"opinion\": opinion})\n",
        "\n",
        "    return rs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAYHj7A5WTia"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/nguyenanh-projects/internship-2024/dataset/ds-4-storage/subset-in/subset_3.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3LCh3a8pUvl"
      },
      "outputs": [],
      "source": [
        "data_inference = DataInference(model_name, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZrFpZchiyLF"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "ds4inf = json.load(open(path, 'r', encoding='utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjodBO4ji59J"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "outpath = f\"/content/drive/MyDrive/nguyenanh-projects/internship-2024/dataset/ds-4-storage/subset-out/sub-3/\"\n",
        "\n",
        "def ccc(outpath, start_index, end_index):\n",
        "    filepath = outpath + f\"storage-out-sub-3-{start_index}-{end_index}.json\"\n",
        "\n",
        "    outfile = open(filepath, 'w', encoding=\"utf-8\")\n",
        "    rs = []\n",
        "\n",
        "    # 0 - 300 - 600 - 900 - 1300 - 1600 - 1900 - 2200 - 2500 - 2800\n",
        "    # 3100 - 3400 - 3700 - 4000 - 4300 - 4600 - 4900 - 5200 - 5500 - 5800\n",
        "    # 6100 - 6400 - 6700 - 7000 - 7300 - 7600 - 7900 - 8100 - 8400 - 8700\n",
        "    # 9000 - 9300 - 9600 - 9900.\n",
        "\n",
        "    for point in ds4inf[start_index:end_index]:\n",
        "      point[\"result\"] = data_inference.inference_pipeline(point[\"review\"])\n",
        "      print(point)\n",
        "      rs.append(point)\n",
        "      time.sleep(10)\n",
        "\n",
        "    json.dump(rs, outfile, indent=4, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ccc(outpath, 30, 170)"
      ],
      "metadata": {
        "id": "Bi1A824JAgaz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}